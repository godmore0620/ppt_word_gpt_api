from flask import Flask, request, jsonify
import os

app = Flask(__name__)

# â³ å»¶é²åˆå§‹åŒ–ï¼šé¦–æ¬¡ API è«‹æ±‚æ‰è¼‰å…¥æ¨¡å‹èˆ‡æ–‡ä»¶
qa = None

@app.route("/ask", methods=["POST"])
def ask():
    global qa
    data = request.get_json()
    query = data.get("question")

    if not query:
        return jsonify({"error": "ç¼ºå°‘å•é¡Œå…§å®¹"}), 400

    # é¦–æ¬¡è«‹æ±‚æ‰åˆå§‹åŒ–æ¨¡å‹èˆ‡å‘é‡è³‡æ–™åº«
    if qa is None:
        try:
            from langchain.embeddings import HuggingFaceEmbeddings
            from langchain.vectorstores import FAISS
            from langchain.text_splitter import RecursiveCharacterTextSplitter
            from langchain.llms import HuggingFaceHub
            from langchain.chains import RetrievalQA
            import pptx
            import docx

            def extract_text_from_pptx(path):
                prs = pptx.Presentation(path)
                text = []
                for slide in prs.slides:
                    for shape in slide.shapes:
                        if hasattr(shape, "text"):
                            text.append(shape.text)
                return "\n".join(text)

            def extract_text_from_docx(path):
                doc = docx.Document(path)
                return "\n".join([p.text for p in doc.paragraphs if p.text.strip()])

            def load_documents():
                texts = []
                for fname in os.listdir("docs"):
                    fpath = os.path.join("docs", fname)
                    if fname.endswith(".pptx"):
                        texts.append(extract_text_from_pptx(fpath))
                    elif fname.endswith(".docx"):
                        texts.append(extract_text_from_docx(fpath))
                return "\n".join(texts)

            print("âœ… æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹èˆ‡æ–‡ä»¶...")
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
            documents = load_documents()
            texts = text_splitter.split_text(documents)
            embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
            db = FAISS.from_texts(texts, embeddings)
            retriever = db.as_retriever()

            llm = HuggingFaceHub(
                repo_id="google/flan-t5-base",
                model_kwargs={"temperature": 0.5, "max_new_tokens": 256}
            )
            qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
            print("âœ… åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            return jsonify({"error": f"åˆå§‹åŒ–å¤±æ•—ï¼š{str(e)}"}), 500

    try:
        result = qa.run(query)
        return jsonify({"answer": result})
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# ğŸŸ¢ ç‚º Render è¨­å®šæ­£ç¢ºçš„ host/port
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    print(f"ğŸš€ App running on port {port}")
    app.run(host="0.0.0.0", port=port)
